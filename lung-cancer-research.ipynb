{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-26T17:36:06.474276Z",
     "iopub.status.busy": "2025-06-26T17:36:06.474037Z",
     "iopub.status.idle": "2025-06-26T17:36:06.477889Z",
     "shell.execute_reply": "2025-06-26T17:36:06.477234Z",
     "shell.execute_reply.started": "2025-06-26T17:36:06.474248Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install opencv-python scikit-learn pandas numpy matplotlib tensorflow-addons\n",
    "# !pip install tensorflow==2.12 keras==2.12\n",
    "# !pip install transformers datasets torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T17:36:08.815927Z",
     "iopub.status.busy": "2025-06-26T17:36:08.815178Z",
     "iopub.status.idle": "2025-06-26T17:36:36.375222Z",
     "shell.execute_reply": "2025-06-26T17:36:36.374648Z",
     "shell.execute_reply.started": "2025-06-26T17:36:08.815905Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 17:36:13.016058: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750959373.549138      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750959373.683010      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import kagglehub\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Conv2D, Multiply, GlobalAveragePooling2D, Dense, Input, Softmax, Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T17:36:41.025067Z",
     "iopub.status.busy": "2025-06-26T17:36:41.024175Z",
     "iopub.status.idle": "2025-06-26T17:37:03.515070Z",
     "shell.execute_reply": "2025-06-26T17:37:03.514243Z",
     "shell.execute_reply.started": "2025-06-26T17:36:41.025041Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "import requests\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "from torch.optim import AdamW \n",
    "from transformers import ViTFeatureExtractor\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T17:37:17.982440Z",
     "iopub.status.busy": "2025-06-26T17:37:17.981805Z",
     "iopub.status.idle": "2025-06-26T17:37:18.210316Z",
     "shell.execute_reply": "2025-06-26T17:37:18.209666Z",
     "shell.execute_reply.started": "2025-06-26T17:37:17.982415Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /kaggle/input/iqothnccd-lung-cancer-dataset\n",
      "Path to dataset files: /kaggle/input/the-cancer-imaging-archive-lidcidri\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"adityamahimkar/iqothnccd-lung-cancer-dataset\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "path = kagglehub.dataset_download(\"justinkirby/the-cancer-imaging-archive-lidcidri\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T17:37:20.402625Z",
     "iopub.status.busy": "2025-06-26T17:37:20.402032Z",
     "iopub.status.idle": "2025-06-26T17:37:20.406204Z",
     "shell.execute_reply": "2025-06-26T17:37:20.405538Z",
     "shell.execute_reply.started": "2025-06-26T17:37:20.402585Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/kaggle/input/iqothnccd-lung-cancer-dataset/The IQ-OTHNCCD lung cancer dataset/The IQ-OTHNCCD lung cancer dataset'\n",
    "test_dir = '/kaggle/input/iqothnccd-lung-cancer-dataset/Test cases'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T17:37:23.039653Z",
     "iopub.status.busy": "2025-06-26T17:37:23.039029Z",
     "iopub.status.idle": "2025-06-26T17:37:25.519314Z",
     "shell.execute_reply": "2025-06-26T17:37:25.518470Z",
     "shell.execute_reply.started": "2025-06-26T17:37:23.039628Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 878 images belonging to 3 classes.\n",
      "Found 219 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "img_size = (224, 224)\n",
    "batch_size = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T17:37:28.629624Z",
     "iopub.status.busy": "2025-06-26T17:37:28.629009Z",
     "iopub.status.idle": "2025-06-26T17:37:28.633680Z",
     "shell.execute_reply": "2025-06-26T17:37:28.632906Z",
     "shell.execute_reply.started": "2025-06-26T17:37:28.629569Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bengin cases': 0, 'Malignant cases': 1, 'Normal cases': 2}\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T17:37:30.623336Z",
     "iopub.status.busy": "2025-06-26T17:37:30.623036Z",
     "iopub.status.idle": "2025-06-26T17:37:30.632879Z",
     "shell.execute_reply": "2025-06-26T17:37:30.632165Z",
     "shell.execute_reply.started": "2025-06-26T17:37:30.623313Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: 3.048611111111111, 1: 0.651818856718634, 2: 0.8788788788788788}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "y_train = train_generator.classes  \n",
    "\n",
    "#Compute class weightss\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "# Convert to dict for Keras\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "print(\"Class Weights:\", class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T17:37:33.583060Z",
     "iopub.status.busy": "2025-06-26T17:37:33.582734Z",
     "iopub.status.idle": "2025-06-26T17:37:35.113749Z",
     "shell.execute_reply": "2025-06-26T17:37:35.113121Z",
     "shell.execute_reply.started": "2025-06-26T17:37:33.583037Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6ad3ee19f84041a66db871b47ed4d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from transformers import ViTImageProcessor\n",
    "import cv2\n",
    "\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "\n",
    "def custom_preprocess(img):\n",
    "    # Convert PIL Image to numpy array\n",
    "    img_np = np.array(img)\n",
    "    if img_np.ndim == 3 and img_np.shape[2] == 3:\n",
    "        img_np = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
    "    # CLAHE\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    img_np = clahe.apply(img_np)\n",
    "    # Bicubic interpolation (resize)\n",
    "    img_np = cv2.resize(img_np, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    # Gaussian Blurring\n",
    "    img_np = cv2.GaussianBlur(img_np, (5,5), 0)\n",
    "    # Thresholding\n",
    "    _, img_np = cv2.threshold(img_np, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    # Erosion\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    img_np = cv2.erode(img_np, kernel, iterations=1)\n",
    "    # Dilation\n",
    "    img_np = cv2.dilate(img_np, kernel, iterations=1)\n",
    "    # Convert back to PIL Image\n",
    "    return Image.fromarray(img_np)\n",
    "\n",
    "# Update your train_transform and val_transform\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Lambda(custom_preprocess),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),  # Convert to 3 channels if needed\n",
    "    transforms.Normalize(mean=processor.image_mean, std=processor.image_std)\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Lambda(custom_preprocess),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),  # Convert to 3 channels if needed\n",
    "    transforms.Normalize(mean=processor.image_mean, std=processor.image_std)\n",
    "])\n",
    "\n",
    "full_dataset = datasets.ImageFolder(root=data_dir)\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "train_dataset.dataset.transform = train_transform\n",
    "val_dataset.dataset.transform = val_transform\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T17:37:45.877086Z",
     "iopub.status.busy": "2025-06-26T17:37:45.876322Z",
     "iopub.status.idle": "2025-06-26T17:37:47.939270Z",
     "shell.execute_reply": "2025-06-26T17:37:47.938673Z",
     "shell.execute_reply.started": "2025-06-26T17:37:45.877062Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff103dd4b7254dd69d03882770bdaedf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c619fef761e438888faad0671f5fc38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(full_dataset.classes)\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    'google/vit-base-patch16-224-in21k',\n",
    "    num_labels=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T17:37:50.398878Z",
     "iopub.status.busy": "2025-06-26T17:37:50.398293Z",
     "iopub.status.idle": "2025-06-26T17:37:50.402402Z",
     "shell.execute_reply": "2025-06-26T17:37:50.401588Z",
     "shell.execute_reply.started": "2025-06-26T17:37:50.398850Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_model_state = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T17:37:56.400164Z",
     "iopub.status.busy": "2025-06-26T17:37:56.399471Z",
     "iopub.status.idle": "2025-06-26T17:37:56.732321Z",
     "shell.execute_reply": "2025-06-26T17:37:56.731716Z",
     "shell.execute_reply.started": "2025-06-26T17:37:56.400143Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "train_labels = [full_dataset.samples[i][1] for i in train_dataset.indices]\n",
    "\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_labels),\n",
    "    y=train_labels\n",
    ")\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_model_state = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T17:38:00.515999Z",
     "iopub.status.busy": "2025-06-26T17:38:00.515402Z",
     "iopub.status.idle": "2025-06-26T17:48:12.522041Z",
     "shell.execute_reply": "2025-06-26T17:48:12.521327Z",
     "shell.execute_reply.started": "2025-06-26T17:38:00.515977Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 20.0034\n",
      "Validation Loss: 0.5446, Accuracy: 0.9000\n",
      "✅ Best model updated.\n",
      "Epoch 2, Train Loss: 9.5773\n",
      "Validation Loss: 0.4553, Accuracy: 0.9364\n",
      "✅ Best model updated.\n",
      "Epoch 3, Train Loss: 5.6990\n",
      "Validation Loss: 0.2080, Accuracy: 0.9636\n",
      "✅ Best model updated.\n",
      "Epoch 4, Train Loss: 3.3641\n",
      "Validation Loss: 0.1794, Accuracy: 0.9545\n",
      "✅ Best model updated.\n",
      "Epoch 5, Train Loss: 2.5548\n",
      "Validation Loss: 0.2909, Accuracy: 0.8773\n",
      "Epoch 6, Train Loss: 1.7609\n",
      "Validation Loss: 0.0886, Accuracy: 0.9909\n",
      "✅ Best model updated.\n",
      "Epoch 7, Train Loss: 1.2374\n",
      "Validation Loss: 0.0847, Accuracy: 0.9773\n",
      "✅ Best model updated.\n",
      "Epoch 8, Train Loss: 0.9194\n",
      "Validation Loss: 0.0834, Accuracy: 0.9818\n",
      "✅ Best model updated.\n",
      "Epoch 9, Train Loss: 1.0352\n",
      "Validation Loss: 0.1589, Accuracy: 0.9727\n",
      "Epoch 10, Train Loss: 0.6506\n",
      "Validation Loss: 0.0764, Accuracy: 0.9818\n",
      "✅ Best model updated.\n",
      "Epoch 11, Train Loss: 0.5371\n",
      "Validation Loss: 0.0719, Accuracy: 0.9909\n",
      "✅ Best model updated.\n",
      "Epoch 12, Train Loss: 0.4772\n",
      "Validation Loss: 0.0728, Accuracy: 0.9909\n",
      "Epoch 13, Train Loss: 0.4325\n",
      "Validation Loss: 0.0736, Accuracy: 0.9909\n",
      "Epoch 14, Train Loss: 0.3958\n",
      "Validation Loss: 0.0738, Accuracy: 0.9909\n",
      "Epoch 15, Train Loss: 0.3641\n",
      "Validation Loss: 0.0742, Accuracy: 0.9909\n",
      "Best model saved to 'best_vit_model.pth'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "import copy\n",
    "\n",
    "# Prepare labels for stratification\n",
    "all_labels = [sample[1] for sample in full_dataset.samples]\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold = 1\n",
    "best_fold_accuracies = []\n",
    "\n",
    "for train_idx, val_idx in skf.split(np.zeros(len(all_labels)), all_labels):\n",
    "    print(f\"\\n===== Fold {fold} =====\")\n",
    "    train_subset = Subset(full_dataset, train_idx)\n",
    "    val_subset = Subset(full_dataset, val_idx)\n",
    "    # Set transforms\n",
    "    train_subset.dataset.transform = train_transform\n",
    "    val_subset.dataset.transform = val_transform\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Compute class weights for this fold\n",
    "    train_labels_fold = [all_labels[i] for i in train_idx]\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(train_labels_fold),\n",
    "        y=train_labels_fold\n",
    "    )\n",
    "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "    # Re-initialize model for each fold\n",
    "    model = ViTForImageClassification.from_pretrained(\n",
    "        'google/vit-base-patch16-224-in21k',\n",
    "        num_labels=num_classes\n",
    "    ).to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(10):  # You can adjust epochs\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs).logits\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs).logits\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        accuracy = correct / total\n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {total_loss:.4f}\")\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            best_fold_accuracy = accuracy\n",
    "            print(\"✅ Best model updated.\")\n",
    "    # Save best model for this fold\n",
    "    torch.save(best_model_state, f\"best_vit_model_fold{fold}.pth\")\n",
    "    print(f\"Best model for fold {fold} saved to 'best_vit_model_fold{fold}.pth'\")\n",
    "    best_fold_accuracies.append(best_fold_accuracy)\n",
    "    fold += 1\n",
    "\n",
    "print(\"Cross-validation complete.\")\n",
    "print(\"Fold Accuracies:\", best_fold_accuracies)\n",
    "print(\"Mean Accuracy:\", np.mean(best_fold_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T17:48:45.628015Z",
     "iopub.status.busy": "2025-06-26T17:48:45.627382Z",
     "iopub.status.idle": "2025-06-26T17:48:49.621955Z",
     "shell.execute_reply": "2025-06-26T17:48:49.621081Z",
     "shell.execute_reply.started": "2025-06-26T17:48:45.627988Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   Bengin cases       0.97      0.97      0.97        31\n",
      "Malignant cases       1.00      1.00      1.00       104\n",
      "   Normal cases       0.99      0.99      0.99        85\n",
      "\n",
      "       accuracy                           0.99       220\n",
      "      macro avg       0.99      0.99      0.99       220\n",
      "   weighted avg       0.99      0.99      0.99       220\n",
      "\n",
      "Accuracy: 0.9909\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        logits = model(inputs).logits\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "print(classification_report(all_labels, all_preds, target_names=full_dataset.classes))\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1748489,
     "isSourceIdPinned": false,
     "sourceId": 2882784,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2787116,
     "isSourceIdPinned": false,
     "sourceId": 4813218,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
